# Make sure to replace placeholder paths to config files and model directories

x-env: &env
  environment:
    # Make sure you `export` your self-hosted API key secret in your local environment
    DEEPGRAM_API_KEY: "${DEEPGRAM_API_KEY}"
    DEEPGRAM_DEPLOYMENT_ORCHESTRATOR: "docker-compose"

services:
  # The speech API service.
  api:
    image: quay.io/deepgram/self-hosted-api:release-250731
    restart: always

    # Here we expose the API port to the host machine. The container port
    # (right-hand side) must match the port that the API service is listening
    # on (from its configuration file).
    ports:
      - "8080:8080"

    <<: *env

    # The path on the left of the colon ':' should point to files/directories on the host machine.
    # The path on the right of the colon ':' is an in-container path. It must match the path
    #     specified in the `command` header below.
    volumes:
      - "/path/to/api.toml:/api.toml:ro,Z"

    # Invoke the API server
    command: -v serve /api.toml

    # Make sure the License Proxy is available for licensing
    depends_on:
      - license-proxy

  # The speech engine service.
  engine:
    image: quay.io/deepgram/self-hosted-engine:release-250731
    restart: always

    # Utilize a GPU, if available.
    runtime: nvidia

    ports:
      - "9991:9991"

    <<: *env

    # The path on the left of the colon ':' should point to files/directories on the host machine.
    # The path on the right of the colon ':' is an in-container path.
    volumes:
      # In-container models path below must match the one specified in the Engine configuration file. The default location is "/models"
      - "/path/to/models:/models:ro,Z"
      # In-container config path below must match the path specified in the `command` header below.
      - "/path/to/engine.toml:/engine.toml:ro,Z"

    # Invoke the Engine service
    command: -v serve /engine.toml

    # Make sure the License Proxy is available for licensing
    depends_on:
      - license-proxy

  # The service to validate your Deepgram license
  license-proxy:
    image: quay.io/deepgram/self-hosted-license-proxy:release-250731
    restart: always

    # Here we expose the License Proxy status port to the host machine. The container port
    # (right-hand side) must match the port that the License Proxy service is listening
    # on (from its configuration file).
    ports:
      - "8089:8080"

    <<: *env

    # The path on the left of the colon ':' should point to files/directories on the host machine.
    # The path on the right of the colon ':' is an in-container path. It must match the path
    #     specified in the `command` header below.
    volumes:
      - "/path/to/license-proxy.toml:/license-proxy.toml:ro,Z"

    # Invoke the License Proxy service
    command: -v serve /license-proxy.toml
