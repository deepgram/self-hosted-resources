# Make sure to replace placeholder paths to config files and model directories

services:
  # The speech API service.
  api:
    image: quay.io/deepgram/self-hosted-api:release-250130

    # Here we expose the API port to the host machine. The container port
    # (right-hand side) must match the port that the API service is listening
    # on (from its configuration file).
    ports:
      - "8080:8080"

    # Make sure you `export` your self-hosted API key secret in your local environment
    environment:
      DEEPGRAM_API_KEY: "${DEEPGRAM_API_KEY}"
      DEEPGRAM_DEPLOYMENT_ORCHESTRATOR: "podman-compose"

    # The path on the left of the colon ':' should point to files/directories on the host machine.
    # The path on the right of the colon ':' is an in-container path. It must match the path
    #     specified in the `command` header below.
    volumes:
      - "/path/to/api.toml:/api.toml:ro,Z"

    # Invoke the API server
    command: -v serve /api.toml

  # The speech engine service.
  engine:
    image: quay.io/deepgram/self-hosted-engine:release-250130

    # Utilize a GPU, if available.
    devices:
      - nvidia.com/gpu=all

    ports:
      - "9991:9991"

    # Make sure you `export` your self-hosted API key secret in your local environment
    environment:
      DEEPGRAM_API_KEY: "${DEEPGRAM_API_KEY}"
      DEEPGRAM_DEPLOYMENT_ORCHESTRATOR: "podman-compose"

    # The path on the left of the colon ':' should point to files/directories on the host machine.
    # The path on the right of the colon ':' is an in-container path.
    volumes:
      # In-container models path below must match the one specified in the Engine configuration file. The default location is "/models"
      - "/path/to/models:/models:ro,Z"
      # In-container config path below must match the path specified in the `command` header below.
      - "/path/to/engine.toml:/engine.toml:ro,Z"

    # Invoke the Engine service
    command: -v serve /engine.toml
