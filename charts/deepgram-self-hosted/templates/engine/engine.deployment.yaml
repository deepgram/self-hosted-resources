apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.engine.namePrefix }}
  labels: &labels
{{ include "deepgram-self-hosted.labels" . | indent 4}}
    app: deepgram-engine 
    {{- range $key, $val := .Values.engine.additionalLabels }}
    {{ $key }}: {{ $val | quote }}
    {{- end}}
spec:
  selector:
    matchLabels:
      app: deepgram-engine
      {{ include "deepgram-self-hosted.selectorLabels" . }} 
  replicas: {{ .Values.scaling.static.engine.replicas }}
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: {{ .Values.engine.updateStrategy.rollingUpdate.maxUnavailable }}
      maxSurge: {{ .Values.engine.updateStrategy.rollingUpdate.maxSurge }}
  template:
    metadata:
      labels: *labels
    spec:
      terminationGracePeriodSeconds: {{ .Values.global.outstandingRequestGracePeriod }}
      imagePullSecrets:
      - name: {{ required "Missing image repository credentials - see `global.pullSecretRef`" .Values.global.pullSecretRef }}
      {{- with .Values.engine.nodeSelector }}
      {{- if . }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- end }}
      containers:
      - name: {{ .Values.engine.namePrefix }}
        image: {{ .Values.engine.image.path }}:{{ .Values.engine.image.tag }}
        imagePullPolicy: {{ .Values.engine.image.pullPolicy }}
        envFrom:
        - secretRef:
            name: {{ required "Missing Deepgram onprem API key - see `global.deepgramSecretRef`" .Values.global.deepgramSecretRef }}
        {{- if le (int .Values.engine.resources.requests.gpu) 0 }}
        env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "void"
        {{- end }}
        command: [ "impeller" ]
        args: ["-v", "serve", "/etc/config/engine.toml"]
        resources:
          requests:
            memory: "{{ .Values.engine.resources.requests.memory }}"
            cpu: "{{ .Values.engine.resources.requests.cpu }}"
            {{- if gt (int .Values.engine.resources.requests.gpu) 0 }}
            nvidia.com/gpu: {{ .Values.engine.resources.requests.gpu }}
            {{- end }}
          limits:
            memory: "{{ .Values.engine.resources.limits.memory }}"
            cpu: "{{ .Values.engine.resources.limits.cpu }}"
            {{- if gt (int .Values.engine.resources.limits.gpu) 0 }}
            nvidia.com/gpu: {{ .Values.engine.resources.limits.gpu }}
            {{- end }}
        volumeMounts:
        - name: engine-config-volume
          mountPath: /etc/config
        - name: models-volume
          mountPath: {{ index .Values.engine.modelManager.searchPaths 0 }}
        ports:
        - name: primary
          containerPort: {{ .Values.engine.server.port }}
        - name: metrics
          containerPort: {{ .Values.engine.metricsServer.port }}
        startupProbe:
          tcpSocket:
            port: {{ .Values.engine.server.port }}
          periodSeconds: {{ .Values.engine.startupProbe.periodSeconds }}
          failureThreshold: {{ .Values.engine.startupProbe.failureThreshold }}
        livenessProbe:
          tcpSocket:
            port: {{ .Values.engine.server.port }}
        readinessProbe:
          tcpSocket:
            port: {{ .Values.engine.server.port }}
      volumes:
      - name: engine-config-volume
        configMap:
          name: {{ .Values.engine.namePrefix }}-config
      - name: models-volume
        persistentVolumeClaim:
          {{- if .Values.engine.modelManager.volumes.customVolumeClaim }}
          claimName: {{ .Values.engine.modelManager.volumes.customVolumeClaim }}
          {{- else if .Values.engine.modelManager.volumes.aws.efs.enabled }}
          claimName: {{ .Values.engine.modelManager.volumes.aws.efs.namePrefix }}-aws-efs-pvc
          {{- end }}
