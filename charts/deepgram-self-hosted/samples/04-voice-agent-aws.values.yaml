# See the Chart [README](https://github.com/deepgram/self-hosted-resources/blob/main/charts/deepgram-self-hosted#values)
#   for documentation on all available options.

global:
  # pullSecretRef should refer to a K8s secret that
  # must be created prior to installing this Chart.
  # Consult the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/secret/) for best practices on configuring Secrets for use in your cluster.
  #
  # You can create a secret for your image pull credentials
  # with the following commands:
  # ```bash
  # docker login quay.io
  # kubectl create secret docker-registry dg-regcred \
  #   --docker-server=quay.io \
  #   --docker-username='QUAY_DG_USER' \
  #   --docker-password='QUAY_DG_PASSWORD'
  # ```
  pullSecretRef: "dg-regcred"

  # deepgramSecretRef should refer to a K8s secret that
  # must be created prior to installing this Chart.
  # Consult the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/secret/) for best practices on configuring Secrets for use in your cluster.
  #
  # You can create a secret for your Deepgram self-hosted API key
  # with the following command:
  # ```bash
  # kubectl create secret generic dg-self-hosted-api-key --from-literal=DEEPGRAM_API_KEY='<id>'
  # ```
  deepgramSecretRef: "dg-self-hosted-api-key"

  # Third-party providers for Voice Agent.
  # For each provider you'd like to configure, uncomment its line and insert your API key.
  # Make sure to preserve the indentation under the `thirdPartyCredentials` header.
  thirdPartyCredentials:
    # openAiSecretRef: "openai-api-key"
    # anthropicSecretRef: "anthropic-api-key"
    # groqSecretRef: "groq-api-key"
    # elevenLabsSecretRef: "elevenlabs-api-key"
    # cartesiaSecretRef: "cartesia-api-key"
    # xaiSecretRef: "xai-secret-ref"

scaling:
  replicas:
    api: 1
    engine: 1
  auto:
    # Can toggle to true to enable autoscaling. Make sure to set a value for one of the available metrics
    enabled: false
    engine:
      metrics:
        speechToText:
          batch:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
          streaming:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
        textToSpeech:
          batch:
            requestsPerPod: # Discuss a reasonable value with your Deepgram Account Representative
        # Discuss a reasoanble value with your Deepgram Account Representative
        # Must also set engine.concurrencyLimit.activeRequests if using request ratio for autoscaling
        requestCapacityRatio:

agent:
  enabled: true
  eotTimeoutMs: 3500
  maxConversationChars: 15000
  llmProviders: # Add the LLM providers and models of your choosing
    open_ai:
      name: "OpenAI"
      models:
        gpt-4o-mini:
          name: "GPT-4o mini"
          tier: "standard"
          public: true
        gpt-3-5-turbo:
          name: "GPT-3.5 Turbo"
          tier: "standard"
          public: false
        gpt-4o:
          name: "GPT-4o"
          tier: "advanced"
          public: false
    anthropic:
      name: "Anthropic"
      models:
        claude-3-haiku-20240307:
          name: "Claude 3 Haiku"
          tier: "standard"
          public: true
        claude-3-opus-20240229:
          name: "Claude 3 Opus"
          tier: "advanced"
          public: false
        claude-3-5-haiku-20241022:
          name: "Claude 3.5 Haiku"
          tier: "standard"
          public: false
        claude-3-5-sonnet-20240620:
          name: "Claude 3.5 Sonnet"
          tier: "advanced"
          public: false
        claude-3-5-sonnet-latest:
          name: "Claude 3.5 Sonnet"
          tier: "advanced"
          public: false
    groq:
      name: "Groq"
      models:
        mixtral-8x7b-32768:
          name: "Mixtral 8x7B"
          tier: "standard"
          public: false
        llama3-8b-8192:
          name: "Llama 3 8B"
          tier: "standard"
          public: false
        llama3-70b-8192:
          name: "Llama 3 70B"
          tier: "advanced"
          public: false
    deepgram:
      name: "Deepgram"
      models:
        llama-3-1-8b-instruct:
          name: "Llama 3.1 8B Instruct"
          tier: "standard"
          public: false
    x_ai:
      name: "xAI"
      models:
        grok-2-latest:
          name: "Grok 2 Latest"
          tier: "standard"
          public: false

api:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - api
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "8Gi"
      cpu: "4000m"

engine:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - engine
  resources:
    requests:
      memory: "28Gi"
      cpu: "6000m"
      gpu: 1
    limits:
      memory: "40Gi"
      cpu: "8000m"
      gpu: 1
  # Discuss a reasonable value with your Deepgram Account Representative
  # If not using autoscaling, can be left empty, but must be set if using
  # autoscaling with scaling.auto.engine.metrics.requestCapacityRatio
  concurrencyLimit:
    activeRequests:

  modelManager:
    volumes:
      aws:
        efs:
          enabled: true
          fileSystemId: fs-xxxxxxxxxxxxxxxx # Replace with your EFS ID
    models:
      add:
        # Recommended Voice Agent models:
        # - Nova-3 non-formatted (nova-3-general.en.non-formatted.streaming.bf05427e.dg)
        # - EOT (end-of-turn.4e9dbd96.dg)
        # - Phonemizer for TTS (phonemizer.en.d6b10ae6.dg)
        # - Aura-2 TTS voice model(s) (e.g. aura-asteria-en.ecb76e9d.dg)
        # - Any other streaming STT models of choice (e.g. Nova-2 instead of Nova-3)
        # - https://link-to-model-1.dg
        # ...
      remove:
        # - https://link-to-old-model-1.dg # Replace these with identifiers for any models already present
        # - https://link-to-old-model-2.dg #   in the EFS that you'd like removed. For a new installation,
        # - name-of-old-model-3.dg #   this will likely be empty.
        # - ...

licenseProxy:
  enabled: true

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: k8s.deepgram.com/node-type
                operator: In
                values:
                  - license-proxy
  resources:
    requests:
      memory: "6Gi"
      cpu: "1500m"
    limits:
      memory: "8Gi"
      cpu: "2000m"

cluster-autoscaler:
  enabled: false # Autoscaling is not yet supported for Voice Agent

gpu-operator:
  enabled: true

  # If using EKS accelerated AMIs based on Amazon Linux 2023 (default with Deepgram guides as of Oct 2024),
  # driver and toolkit come bundled with the AMI.
  #
  # If using other AMIs, such as Ubuntu, you should re-enable the driver and toolkit below.
  driver:
    enabled: false
  toolkit:
    enabled: false
